{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "mGKM1I6ErWC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4feb747-14f9-4d5b-9d44-6b975b032657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "AOuh1xCsrWOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "5-Vbn7ygrWXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0n19jf20rbDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download redrussianarmy/turkish-corpus"
      ],
      "metadata": {
        "id": "dNVuXKs_rdX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac4017c-4706-4be5-c41f-a7aecd1c62b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading turkish-corpus.zip to /content\n",
            " 98% 259M/263M [00:08<00:00, 37.2MB/s]\n",
            "100% 263M/263M [00:08<00:00, 33.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/turkish-corpus.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yxhkIwhs58y",
        "outputId": "7c68c0eb-e15c-42dd-8cc5-7be8a56d11d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/turkish-corpus.zip\n",
            "  inflating: tr_corpus.txt           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_corpus = open('/content/tr_corpus.txt').read().split('.')"
      ],
      "metadata": {
        "id": "gBbKy41ms6C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tr_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8GaqS8UtCvZ",
        "outputId": "cfb00d4f-7ee8-45fe-d124-e2c59c31e85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7980841"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(tr_corpus)"
      ],
      "metadata": {
        "id": "kDLIStJPwYEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
      ],
      "metadata": {
        "id": "4V9nz9hryDoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_corpus_tokenized = []\n",
        "for s in tr_corpus:\n",
        "  tokens_list = tokenizer.tokenize(s, max_length=100, truncation=True)\n",
        "  s_tokenized = ' '.join(tokens_list)\n",
        "  tr_corpus_tokenized.append(s_tokenized)"
      ],
      "metadata": {
        "id": "SN6wVI0xSuG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tr_corpus_tokenized)"
      ],
      "metadata": {
        "id": "TkRhfoSdTNQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272fe642-d31e-4a5e-d0ea-34b1263abf93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7980841"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training sets:"
      ],
      "metadata": {
        "id": "T97DK3vAgABw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_180.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[:180000]:\n",
        "      f.write(\"%s\\n\" % s)\n",
        "\n",
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_360.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[:360000]:\n",
        "      f.write(\"%s\\n\" % s)\n",
        "\n",
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_1080.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[:1080000]:\n",
        "      f.write(\"%s\\n\" % s)\n",
        "\n",
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_4320.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[:4320000]:\n",
        "      f.write(\"%s\\n\" % s)\n",
        "\n",
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_tokenized.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized:\n",
        "      f.write(\"%s\\n\" % s)"
      ],
      "metadata": {
        "id": "aANu2Aj0d0vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation sets:"
      ],
      "metadata": {
        "id": "p0LINM4XgBjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_val_for_180.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[4320000:4356000]: # 36000\n",
        "      f.write(\"%s\\n\" % s)\n",
        "\n",
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_val_for_360.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[4356000:4428000]: # 72000\n",
        "      f.write(\"%s\\n\" % s)\n",
        "\n",
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_val_for_1080.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[4428000:4644000]: # 216000\n",
        "      f.write(\"%s\\n\" % s)\n",
        "\n",
        "with open('/content/drive/MyDrive/tr_corpus_vae/tr_corpus_val_for_4320.txt', 'w') as f:\n",
        "    for s in tr_corpus_tokenized[4644000:5508000]: # 864000\n",
        "      f.write(\"%s\\n\" % s)"
      ],
      "metadata": {
        "id": "Ivkq0s28f_KT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}